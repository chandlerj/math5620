\documentclass[10pt]{article}
\textheight=9.25in \textwidth=7in \topmargin=-.75in
 \oddsidemargin=-0.25in
\evensidemargin=-0.25in
\usepackage{url}  % The bib file uses this
\usepackage{graphicx} %to import pictures
\usepackage{amsmath, amssymb}
\usepackage{theorem, multicol, color}
\usepackage{gfsartemisia-euler}

\setlength{\intextsep}{5mm} \setlength{\textfloatsep}{5mm}
\setlength{\floatsep}{5mm}
\setlength{\parindent}{0em} % new paragraphs are not indented
\setcounter{MaxMatrixCols}{20}
\usepackage{caption}
\captionsetup[figure]{font=small}


%%%%  SHORTCUT COMMANDS  %%%%
\newcommand{\ds}{\displaystyle}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\arc}{\rightarrow}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\blank}{\underline{\hspace{0.33in}}}
\newcommand{\qand}{\quad and \quad}
\renewcommand{\stirling}[2]{\genfrac{\{}{\}}{0pt}{}{#1}{#2}}
\newcommand{\dydx}{\ds \frac{d y}{d x}}
\newcommand{\ddx}{\ds \frac{d}{d x}}
\newcommand{\dvdx}{\ds \frac{d v}{d x}} 

%%%%  footnote style %%%%

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\pagestyle{empty}

\begin{document}

\begin{flushright}
Chandler Justice - A02313187
\end{flushright}
\noindent \underline{\hspace{3in}}\\

\textbf{January 31, 2024}\\

\underline{Local Truncation Error}\\


$\tau_j$ - the error obtained by substituting the exact solution into the finite difference equation\\


for j=1,2,...,m \quad for a given "discretization" we want\\
\[AU = f \Rightarrow AU -F = 0\]
and for the LTE
\[A\hat{U} = F + \tau_j = A\hat{U} -F = \tau_j\]
subtract:
\[(AU-F) - (A\hat{U} -F) = -\tau_j \Rightarrow A(U-\hat{U}) = -\tau_j\]
\[AE = -\tau\]
\[E = -A^{-1} \tau \Rightarrow ||E|| = ||A^{-1}\tau||\]
\[||A^{-1}\tau|| \leq ||A^{-1}||* ||\tau||\]

\textit{aside:}\\
\underline{Frobini's Norm}
\[||A||_F = (\sum_{i=1}^n\sum_{j=1}^n |a_{ij}|^2)^{\frac{1}{2}}\]
\[||Ax|| \leq ||A|| * ||x|| \leq C * ||x||\]
\[\frac{||Ax||}{||x||} \leq C\]
where\\
$||A|| = max_{x \in \R; ||x|| \neq 0} \frac{||Ax||}{||x||} = max_{x \in \R; ||x|| = 1}||Ax||$\\

\underline{P-norms}
\[||x|| = (\sum_{j=1}^m |x_j|^p)^{\frac{1}{p}}\]

\underline{Equation of Norm}
\[||E|| \leq ||A^{-1}|| * ||\tau|| \leq C ||\tau||\]

\underline{Stability:} $||A^{-1}|| \leq C$\\

\textit{properties we desire}
\begin{enumerate}
    \item consistency: $||\tau^h|| \to 0$ as $h \to 0$
    \item Stability: $||E^h|| \leq ||(A^h)^{-1}|| * ||\tau||$
\end{enumerate}

If we have consistency + stability, that implies the method is convergent.\\

\textbf{Example:}
\[\frac{1}{h^2} \begin{bmatrix}
1 & -2 & 1 & ... & 0\\
0 & 1 & -2 & 1 & ...\\
... & ... & ... & ... & ...\\
\end{bmatrix}
\Rightarrow
\begin{bmatrix}
1 & -2 & 1 & ... & 0\\
0 & 1 & -2 & 1 & ...\\
... & ... & ... & ... & ...\\
\end{bmatrix}
U = h^2 F
\]
\[h \to 0 \Rightarrow m \to \infty\]

\textit{Aside:}\\
\[\begin{cases}
u'' = f\\
u(0) = \alpha\\
u(1) = \beta
\end{cases}\]

Assume

\[u(\alpha) = \sum_{j=1}^m a_j \phi_j(x)\]
Where $\phi_j(x)$ is a basis function for a function space\\

\underline{Condition number matrix}\\

let $A \in R^{mxm}$, then $\kappa(A) = ||A|| * ||A^{-1}||$\\
\begin{itemize}
    \item if $\kappa(A) \approx 1 \Rightarrow$ good condition
    \item if $\kappa(A) >> 1 \Rightarrow$ the matrix is poorly conditioned
\end{itemize}

Compute the eigenvalues of $A$ (as defined earlier; a tridiagonal matrix with $[1,-2,1]$)\\
\begin{align*}
Av &= \lambda v\\
\end{align*}

\textbf{Febuary 2, 2024}\\
We want a finite difference method to be
\begin{enumerate}
\item consistent: $|\tau_j \leq Ch^p, \quad p > 0, j = 1,2,...,m|$
\item stability: $||(A^h)^{-1}|| \leq C$
\end{enumerate}

\underline{stability} (for 2-norm for matrices)\\

\textit{notes:} $||A||_2 = \sqrt{p(A^tA)} \Rightarrow$ we need the eigenvalues and eigenvector of $A$.\\
\textit{note:} $A \in \R^{mxm}$ is symmetric\\
\begin{align*}
    &\Rightarrow ||A||_2 = p(a)\\
    &\Rightarrow \text{if } \lambda \text{ is an eigenvalue then } \lambda \in \R\\
    &\Rightarrow ||A^{-1}||_2 = p(A^{-1}) = \overset{\ds \text{max}}{1 \leq p \leq m} |(\lambda_1)^{-1}| = (\overset{\ds \text{min}}{1 \leq p \leq m} |\lambda_0|)^{-1}
\end{align*}

The eigenvalues for $A$ and the compoents of the eigenvector of $A$ are
\begin{align*}
    \lambda_p &= \frac{2}{h^2}(\cos(p \pi h) - 1) \quad \text{$p = 1,2,...,m$}\\
    u_i^p &= \sin(p \pi j h) \quad p = 1,2,...,m , j=1,2,...,m\\
    (Au^p)_j &= \frac{1}{h^2}(u_{j-1}^p - 2u_j^p + u+{j+1}^p)\\
             &= \frac{1}{h^2}(\sin(p \pi (j-1) h) - 2\sin(p \pi j h) + \sin(p \pi (j + 1) h))\\
             &= \frac{1}{h^2}(\sin(p \pi j h)\cos(p \pi h) - 2\sin(p \pi j h) + \sin(p \pi j h)\cos(p \pi j h))\\
             &= \frac{1}{h^2} \sin(p \pi j h)(2 \cos(p \pi h) - 2)\\
             &= (\frac{2}{h^2} (cos(p \pi h) - 1)) \sin(p \pi j h)\\
             &\Rightarrow Av_p = \lambda_p v_p\\
             &||A^{-1}|| \leq c\\
\end{align*}


Lets look at $\lambda_1$
\begin{align*}
    \lambda_1 &= \frac{2}{h^2} (\cos(\pi h) - 1)\\
              &= \frac{2}{h^2} ((1 - \frac{(\pi h)^2}{2!} + \frac{(\pi h)^4}{4!} + ...) - 1)\\
              &= -\frac{2}{h^2} (\frac{\pi^2 h^2}{2} + O(h^4))\\
              &= -\pi^2 + O(h^2)\\
  |\lambda_1| &\approx |-\pi^2|\\
              &= \pi^2 \leq C\\
        ||E^h|| &\leq ||(A^h)^{-1}|| * ||\tau^4||\\
                &\leq \pi^2 \leq O(h^2) \Rightarrow \text{implies convergence}
\end{align*}

Sooooooo
\[||\tau^h||_2 = \frac{1}{12} h^2 ||u''''||_2 \leq Ch^2\]
And we know
\begin{align*}
    u'' &= f\\
    u''' &= f'\\
    u'''' &= f''
\end{align*}
which we can use to express
\[\Rightarrow ||\tau^h||_2 = \frac{1}{12}h^2||f''||_2\]

Lets get our own Eigenvalues/Eigenvectors. We have
\[Av  = \lambda v\]
Where $A$ is the \textit{beloved} tridiagonal matrix (with entries $[c,a,b]$ along their respective diagonals) and $v$ is our approximate solutions.
\begin{align*}
    Av &= \lambda v \Rightarrow (A - \lambda I)v = 0\\
       &= (a - \lambda) v_1 + b v_2\\
   A_1 &= c v_1 + (a - \lambda) v_2 + bv_3\\
   A_{...} &= ...\\
   A_m &= c v_{m-1} + (a - \lambda) v_m
\end{align*}
given
\[
    \begin{cases}
    v_0 = 0\\
    v_{m+1} = 0
\end{cases} \Rightarrow c v_{j-1} + (a - \lambda) cj + b_{j+1} \text{ for all } j=1,2,...,m\]

\underline{Second order approximations}
\[\begin{cases}
\alpha y'' + \beta y'' + \gamma y = 0\\
y(0) = 0\\
y(L) = 0
\end{cases} \Rightarrow y = e^{rx}\]
\[\alpha r^2 e^{rx} + \beta r e^{rx} + \gamma e^{rx} = 0 \Rightarrow \gamma = \frac{- \beta +/- \sqrt{\beta^2 - 4 x \alpha}}{2 \alpha}\]

\[\alpha v_{j+1} + \beta v_j + \gamma v_{j-1} = 0\]
\[\begin{cases}
v_j = z^j\\
v_{j-1} = z^{j-1}\\
c_{j+1} = z^{j+1}
\end{cases}\]


\noindent \underline{\hspace{3in}}\\

\end{document}

